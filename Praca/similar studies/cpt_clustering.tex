% !TeX spellcheck = en_EN-English

A necessary prerequisite for predicting a patientâ€™s future is embedding patient records into numerical representations. This process is relatively straightforward for attributes that are already numeric, such as age, or for attributes with structured codes, like diagnoses. However, with medical procedures, a challenge arises: the codes associated with procedures lack a hierarchical structure. As a result, two similar procedures might have completely different codes. To address this, we needed a method to embed procedures so that similar procedures receive similar embeddings. One effective approach is to group medical procedures into clusters, assigning similar embeddings to procedures within the same cluster and dissimilar embeddings to those in different clusters.
\\

Lorenzi et al. from Duke University in Durham developed a novel algorithm called Predictive Hierarchical Clustering \cite{lorenzi2017predictive}. This algorithm was designed for agglomerative clustering of surgical CPT codes. It uses a one-pass, bottom-up approach that utilizes EHR data-specifically, 317 predictors such as lab values and patient history, while excluding CPT information-from 3 723 252 patients and 3 132 CPT codes, where each patient has one main surgical CPT code. For each CPT code, they create a tree containing patients with the corresponding code. Afterwards, at each iteration, the algorithm considers merging all pairs of existing trees. To compare two trees, it uses two hypotheses: the first hypothesis states that the data in both trees are generated from the same model, while the second states that the data in each tree are generated from models with different parameters. The final value is a weighted average of the probabilities of these two hypotheses, considering the data in the trees, where the weight is the probability of the first hypothesis which formula is shown in Eq. \ref{hierClust}.

\begin{equation}
	\label{hierClust}
	p(D_k \vert T_k) = p(H_1^k)p(D_k \vert H_1^k) + (1 - p(H_1^k))p(D_i \vert T_i)p(D_j \vert T_j)
\end{equation} 

Where $D_k$ is the set of data in the merged tree (formed by merging $T_i$ and $T_j$), $T_k$ is the merged tree, $H_1^k$ is the first hypothesis, and $D_i$ and $D_j$ are the data in trees $T_i$ and $T_j$. During experimental testing, they compared the results of their approach to clustering CPT codes into 16 clinical groups. To evaluate performance, they used both their clustering method and clinical clustering to predict additional procedures for patients in a validation group, then computed the area under the receiver operating characteristic curve (AUROC) and the area under the precision-recall curve (AUROC). Their model achieved a few percentage points of improvement in these metrics compared to clinical clustering.
\\

In the end, we decided not to use this approach in our work, as it cannot reliably distinguish whether two procedures are considered similar due to their actual similarity or simply because they frequently occur together as part of the determination or treatment of a specific diagnosis. This distinction is important, since procedures that only appear together may have vastly different costs associated with them, which could pose issues for the prediction model.