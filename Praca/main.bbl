\newcommand{\noopsort}[1]{} \newcommand{\printfirst}[2]{#1}
  \newcommand{\singleletter}[1]{#1} \newcommand{\switchargs}[2]{#2#1}
\begin{thebibliography}{10}

\bibitem{atc_who}
{A}natomical {T}herapeutic {C}hemical ({A}{T}{C}) {C}lassification --- who.int.
\newblock \url{https://www.who.int/tools/atc-ddd-toolkit/atc-classification}.
\newblock [Accessed 25-09-2024].

\bibitem{word2vec}
{G}it{H}ub - essential-data/word2vec-sk: {V}ector representations of {S}lovak
  words trained using word2vec --- github.com.
\newblock \url{https://github.com/essential-data/word2vec-sk}.
\newblock [Accessed 19-10-2024].

\bibitem{labse_kaggle}
{G}oogle | {L}a{B}{S}{E} | {K}aggle --- kaggle.com.
\newblock
  \url{https://www.kaggle.com/models/google/labse/tensorFlow2/labse/1?tfhub-redirect=true}.
\newblock [Accessed 18-10-2024].

\bibitem{ncziMKCH}
Medzinárodná klasifikácia chorôb - {M}{K}{C}{H}-10 --- nczisk.sk.
\newblock
  \url{https://www.nczisk.sk/Standardy-v-zdravotnictve/Pages/Medzinarodna-klasifikacia-chorob-MKCH-10.aspx}.
\newblock [Accessed 16-09-2024].

\bibitem{labse_hug}
sentence-transformers/{L}a{B}{S}{E} · {H}ugging {F}ace --- huggingface.co.
\newblock \url{https://huggingface.co/sentence-transformers/LaBSE}.
\newblock [Accessed 19-10-2024].

\bibitem{elman_img}
Sivanand Achanta, Rambabu Banoth, Ayushi Pandey, Anandaswarup Vadapalli, and
  Suryakanth~V Gangashetty.
\newblock Contextual representation using recurrent neural network hidden state
  for statistical parametric speech synthesis.
\newblock In {\em SSW}, pages 172--177, 2016.

\bibitem{num_of_vis}
Andreas Berzel, Gillian~Z Heller, and Walter Zucchini.
\newblock Estimating the number of visits to the doctor.
\newblock {\em Australian \& New Zealand Journal of Statistics},
  48(2):213--224, 2006.

\bibitem{caballer2019predicting}
Vicent Caballer-Tarazona, Natividad Guadalajara-Olmeda, and David
  Vivas-Consuelo.
\newblock Predicting healthcare expenditure by multimorbidity groups.
\newblock {\em Health Policy}, 123(4):427--434, 2019.

\bibitem{cdcICD10CM}
CDC.
\newblock {I}{C}{D}-10-{C}{M} --- cdc.gov.
\newblock \url{https://www.cdc.gov/nchs/icd/icd-10-cm/index.html}.
\newblock [Accessed 16-09-2024].

\bibitem{chechulin2014predicting}
Yuriy Chechulin, Amir Nazerian, Saad Rais, and Kamil Malikov.
\newblock Predicting patients with high risk of becoming high-cost healthcare
  users in ontario (canada).
\newblock {\em Healthcare Policy}, 9(3):68, 2014.

\bibitem{choi2018mime}
Edward Choi, Cao Xiao, Walter Stewart, and Jimeng Sun.
\newblock Mime: Multilevel medical embedding of electronic health records for
  predictive healthcare.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{bert_pretr_3}
Alexis Conneau and Guillaume Lample.
\newblock Cross-lingual language model pretraining.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{bert_pretr_1}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In Jill Burstein, Christy Doran, and Thamar Solorio, editors, {\em
  Proceedings of the 2019 Conference of the North {A}merican Chapter of the
  Association for Computational Linguistics: Human Language Technologies,
  Volume 1 (Long and Short Papers)}, pages 4171--4186, Minneapolis, Minnesota,
  June 2019. Association for Computational Linguistics.

\bibitem{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186, 2019.

\bibitem{elman}
Jeffrey~L Elman.
\newblock Finding structure in time.
\newblock {\em Cognitive science}, 14(2):179--211, 1990.

\bibitem{labse_paper}
Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang.
\newblock Language-agnostic bert sentence embedding.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 878--891, 2022.

\bibitem{MLParch}
Miao Jin, Qinzhuo Liao, Shirish Patil, Abdulazeez Abdulraheem, Dhafer
  Al-Shehri, and Guenther Glatz.
\newblock Hyperparameter tuning of artificial neural networks for well
  production estimation considering the uncertainty in initialized parameters.
\newblock {\em ACS omega}, 7(28):24145--24156, 2022.

\bibitem{lorenzi2017predictive}
Elizabeth~C Lorenzi, Stephanie~L Brown, Zhifei Sun, and Katherine Heller.
\newblock Predictive hierarchical clustering: Learning clusters of cpt codes
  for improving surgical outcomes.
\newblock In {\em Machine Learning for Healthcare Conference}, pages 231--242.
  PMLR, 2017.

\bibitem{miotto2016deep}
Riccardo Miotto, Li~Li, and Joel~T Dudley.
\newblock Deep learning to predict patient future diseases from the electronic
  health records.
\newblock In {\em Advances in Information Retrieval: 38th European Conference
  on IR Research, ECIR 2016, Padua, Italy, March 20--23, 2016. Proceedings 38},
  pages 768--774. Springer, 2016.

\bibitem{morid2019healthcare}
Mohammad~Amin Morid, Olivia R~Liu Sheng, Kensaku Kawamoto, Travis Ault, Josette
  Dorius, and Samir Abdelrahman.
\newblock Healthcare cost prediction: Leveraging fine-grain temporal patterns.
\newblock {\em Journal of biomedical informatics}, 91:103113, 2019.

\bibitem{chatGPT}
Online.
\newblock In: Chatgpt vezia 4.
\newblock {\em Available at: OpenAI, URL}, Task:.

\bibitem{bert_pretr_2}
Yi~Sun, Yu~Zheng, Chao Hao, and Hangping Qiu.
\newblock Nsp-bert: A prompt-based few-shot learner through an original
  pre-training task--next sentence prediction.
\newblock {\em arXiv preprint arXiv:2109.03564}, 2021.

\bibitem{attentionAllYouNeed}
A~Vaswani.
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 2017.

\end{thebibliography}
